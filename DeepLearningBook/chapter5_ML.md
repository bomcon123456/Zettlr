1. Machine Learning is essentially a form of what?
- Machine learning is essentially a form of applied statistics with increased emphasis on the use of computers to statistically estimate complicated functions and a decreased emphasis on proving confidence intervals around these functions
2. What is the 2 central approaches to statistics in ML?
- frequentist estimators and Bayesian inference.
3. What is an example?
- Example is a collection of features that have been quantitatively measured from some object or event that we want the machine learning system to process.
4. What is an data point?
- Another way to call example
5. What is unsupervised learning?
- experience a dataset containing many features, then learn useful properties of the structure of this dataset
- observing several examples of a random vector $x$, and attempting to implicitly or explicitly learn the probability distribution $p(x)$, or some interesting properties of that distribution.
6. In the context of deep learning, what do we want to learn from the dataset in unsupervised learning?
- Learn the entire probability distribution that generated a dataset; or clustering
7. What is supervised learning?
- experience a dataset containing features, but each example is also associated with a label or target.
- observing several examples of a random vector $x$ and an associated value or vector $y$, and learning to predict $y$ from $x$, usually by estimating $p(y|x)$.

8. What can you say about the relation of unsupervised/ supervised learning when looking at the Chain Rule $p(x) = \displaystyle\prod_{i=1}^{n} p(x_i|x_1,...,x_{i-1})$  ?
- We can solve the unsupervised problem $p(x)$ by splitting into $n$ supervised learning problems.
- Alternatively, we can solve the supervised learning problem of learning $p(y|x)$ by using traditional unsupervised learning technologies to learn tho joint distribution $p(x,y)$ then inferring: $p(y|x) = \frac{p(x,y)}{\sum_{y'}p(x,y')}$.
 9. What is a common way of describing a dataset?
 - Using design matrix
10. What is a design matrix?
- A matrix containing:
    - A different example in each row.
    - Each column of the matrix is a different feature.
11. What are the normal equations?
- The system of equations whose solution is given by equation $w = (X^{(train)T}X^{(train)})^{-1}X^{(train)T}y^{(train)}$ (derived from solving equation $\nabla_w MSE_{train} = 0$).
12. What is generalization?
- The ability to perform well on previously unobserved inputs.
13. What is data generating process?
- The train and test data are generated by a probability distribution over datasets
14. How can we affect performance on the test set when we get to observe only the training set?
- Because we made some assumptions about how the training/test set are collected.
15. What assumption do we generally make for the data?
- We usually make a set of assumptions known collectively as the i.i.d assumptions.
16. What is i.i.d ?
- Idenpendent identicall distributed
- The examples in each dataset are independent
- the train set and test set are identically distributed, drawn from the same probability distribution.
17. Why do we have to make i.i.d assumptions?
- It allows us to describe the data generating process with a probability distribution over a single example.
18. What is the data generating distribution?
- It is the distribution used to generate every train example and every test example.
19. What are the 2 factors to determine how well a ML algorithm will perform?
- Make the training error small.
- Make the gap between training and test error small.
20. What is underfitting?
- Underfitting occurs when the model is not able to obtain a sufficiently low error value on the training set.
21. What is overfitting?
- Overfitting occurs when the gap between the training error and test error is too large
22. What is the model’s capacity?
- A model’s capacity is its ability to fit a wide variety of functions.
23. How to control the capacity of a learning algorithm?
- You can choose its hypothesis space.
25. What is the hypothesis space?
- The set of functions that the learning algorithm is allowed to select as being the solution.
- e.g: the linear regression algorithm has the set of all linear functions of its input as its hypothesis space. we can generalize linear regression to include polynomials, rather than just linear functions, in its hypothesis space. Doing so increases the model’s capacity
26. When will the machine learning algorithm perform best w.r.t their capacity?
- When their capacity is appropriate for the true complexity of the task they need to perform and the amount of training data they are provided with.
27. What is the representational capacity of the model?
- Which family of functions the learning algorithm can choose from when varying the parameters in order to reduce a training objective.

28. In practice, why does the learning algorithm usually can't find the best function?
- Because it's a very difficult optimization problem, so they find one that significantly reduces the training error.
29. What is the principle Occam’s razor?
- Among competing hypotheses that explain known observations equally well, one should choose the “simplest” one.
30. What is the most well-known method to quantify model capacity?
- Vapnik-Chervonenkis dimension, or VC dimension.
31. What does the VC dimension measure?
- It measures the capacity of a binary classifier.
32. How is the VC dimension defined?
- It is defined as being the largest possible value of $m$ for which there exists a training set of $m$ different $x$ points that the classifier can label arbitrarily correctly.
33. The discrepancy between training/generalization error is bound from what?
- From above by a quantity that grows as the model capacity grows but shrinks as the number of training examples increases.

34. Why would these bound (of the discrepancy between training/generalization error) rarely used in deep learning algorithms?
- Because the bounds are often quite loose and because it can be quite difficult to determine the capacity of deep learning algorithms.
35. Why determining the capacity of DL model is hard?
- Because the effective capacity is limited by the capabilities of the optimization algorithm, and we have little theoretical understanding of the very general non-convex optimization problems involved in deep learning.
36. Describe relationship between capacity and error?
![capacity_error.png](..\assets\capacity_error.png)

37. What is the underfitting regime?
- It's when the training error and generalization error are both high
38. What is the overfitting regime?
- It's when the gap between training and generalization error is too big, where capacity is to large, above optimal capacity.
39. What is the optimal capacity?
- It's the capacity where the model perform best.
40. What is parametric model?
- Parametric models learn a function described by a parameter vector whose size is finite and fixed before any data is observed.
41. What is non-parametric model?
- It's the opposite of parametric model. It isn't limited by the parameter vectors.
42. How to design a practical non-parametric models?
- We can make their complexity a function of the training set size.
- e.g: nearest neighbor regression

43. How to make a non-parametric learning algorithm by parametric algorithms?
- By wrapping a parametric learning algorithm inside another algorithm that increases the number of parameters as needed.
- e.g: we could imagine an outer loop of learning that changes the degree of the polynomial learned by linear regression on top of a polynomial expansion of the input
44. What is an ideal model?
- It's an oracle that simply knows the true probability distribution that generates the data
45. Why even such an idel model still can incur errors?
- Because there might be noises in the distribution
46. What is the Bayes error?
- The error incurred by an oracle making predictions from the true distribution p(x, y)
47. ![optimal_capacity.png](..\assets\optimal_capacity.png)

48. What is the No free lunch theorem?
- Averaged over all possible data generating distributions (this theorem only holds when this is true), every classification algorithm has the same error rate when classifying previously unobserved points.
- In some sense, no machine learning algorithm is universally any better than any
other
49. When does the no free lunch theorem is hold?
- Only when we average over all possible data generating distributions (averaging over all possible problems)
50. What is the GOAL of machine learning research?
- The goal is to understand what kinds of distributions are relevant to the “real world” that an AI agent experiences, and what kinds of machine learning algorithms perform well on data drawn from the kinds of data generating distributions we care about.
- Not to seek a universal/best learning algorithm.
51. To help the model choose which function to use in the hypothesis space, what can we do?
- We can give the model a preference.
- This means that when both functions are eligible, only the one that outperforms (fits the data better) the other will be chosen.
52. What is weight decay?
- We add the squared $L_2$ norm to the loss, prereference strength is controlled by parameter $\lambda$
- e.g: linear regression: $J(w) = MSE_{train} + \lambda w^Tw$ 
53. What would happen to the weight when we minimizing $J(w)$ while using weight decay?
- It would make a tradeoff between fitting the training data and being small.
- Give us solutions that have smaller slope or put weight on fewer of the features.

54. What is the regularizer?
- It's a penalty added to the cost function to regularize a model that learn function $f(x;\theta)$.

55. What is the regularization?
- Regularization is any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.

56. Why do we need validation set?
- So that we can tune the hyper parameters

57. What the alternative to 80-20 split when the dataset is too small?
- Cross validation

58. What is the point estimation?
- It's the attempt to provide the single "best" prediction of some quantity of interest.
59. In general, what is the quantity of interest?
- It could be single parameter, a vector of parameters in some parametric model (weights); or the whole function
60. Let $\{x^1,...x^m\}$ be a set of $m$ i.i.d data points. What is a point estimator?
- $\hat{\theta}_m = g(x^1,.., x^m)$ ; where $\hat{\theta}_m$ is close to one that generated the date.
61. What is a good estimator?
- It is a function whose output is close to the true underlying $\theta$ that generated the training data.
62. Taking the frequentist perspective on statistics, what can we say about $\theta; \hat{\theta}$ ?
- $\theta$ (true parameter) is fixed but unknown
- $\hat{\theta}$ is a random variable. Because:
    - $\hat{\theta}$ (point estimation) is a function of data.
    - Since the data is drawn from a random process, any function of the data is random

63. What is function estimators?
- It's the types of point estimates that estimate the relationship between input and target variables.

64. How is the bias of an estimator is defined?
- $bias(\hat{\theta}_m) = E(\hat{\theta}_m) - \theta$  
- where the expectation is over the data (seen as samples from a random variable), $\theta$ is the true underlying value used to define the data generating distribution.
65. What does the bias measure?
- It measures the expected deviation from the true value of the function/ parameter.
67. When is an estimator said to be unbiased?
- If $bias(\hat{\theta}_m) = 0$, implies $E(\hat{\theta}_m) = \theta$.

65. When is an estimator said to be asymtotically unbiased?
- If $\lim_{m \to \infty} bias(\hat{\theta}_m) = 0$ , implies $\lim_{m \to \infty}E(\hat{\theta}_m) = \theta$ dis

66. What is the common estimator for the mean of Bernoulli distribution:
- Sample mean: $\hat{\theta}_m = \frac{1}{m} \displaystyle\sum_{i=1}^{m} x^i$ 

67. What is the common estimator for the variance of Gaussian distribution:
- Unbiased Sample variance: $\hat{\sigma}_m^2 = \frac{1}{m-1} \displaystyle\sum _{i=1}^m (x^i - \hat{\mu}_m)^2$ . (page 142 of DL book)

69. What is the standard error?
- It's the square root of the variance

70. What does the variance or the standard error provide?
- They provide a measure of how we would except the estimate we compute from data to vary as we independently resample the dataset from the underlying data generating process.

71. How to compute the standard error of the mean:
![SE_of_mean.png](..\assets\SE_of_mean.png); where $\sigma^2$ is the true variance of the samples $x^i$
72. What can we use the standard error of the mean for?
- We can use the standard error to compute the probability that the true expectation
falls in any chosen interval. Since:
    it would often estimate the generalization error by computing the sample mean of the error on the test set
    The number of examples in the test set determines the accuracy of this estimate
    Based on central limit theorom, the mean will be approximately distributed with a norm distribution

73. What are some ways to choose model when it comes to the Bias and Variance trade-off?
- Cross-validation (empirically, this is highly successful)
- Compare MSE of the estimate

74. How to compose MSE from Bias and Variance?
$MSE = Bias(\hat{\theta}_m)^2 + Var(\hat{\theta}_m)$ 
![proof_mse.png](..\assets\proof_mse.png)

75. What is consistency in teams of DL?
- $p\lim_{m \to \infty} \hat{\theta}_m = \theta$
- plim means that as $m \to \infty$ , the probability  $P(|\hat{\theta}_m - \theta| > \epsilon) \to 0$  

76. What does the consistency property ensure?
- It ensure that as the number of data examples grows, bias induced by the estimator diminishes (not the other way around)

77. What is a common principle from which we can derive specific functions that are good estimators?
- Maximum likelihood principle.

78. ![given_maxlikelihood.png](..\assets\given_maxlikelihood.png)

What is the maximum likelihood principle?
![Maxlikihood.png](..\assets\Maxlikihood.png)

79. Since product might cause numerical underflow, what should we do to the maximum likelihood?
- We take the logarithm of it to convert to sum
![log_maxlikelihood.png](..\assets\log_maxlikelihood.png)

80. Why would we divide the log maximum likelihood?
- Since the argmax doesn't change when rescaling the cost function
- We will divide by m to obtain a version of the criterion that is expressed as an expectation w.r.t the empirical distribution $\hat{p}_{data}$ (training set):
![expectation_maxlikelihood.png](..\assets\expectation_maxlikelihood.png)
81. How to interpret maximum likelihood using KL divergence?
- View it as minimizaing the dissimilarity between the empirical distribution $\hat{p}_{data}$ (training set) and the model distribution.
- ![kldiver_maxlikelihood.png](..\assets\kldiver_maxlikelihood.png)                                  
82. What can we notice when we minimizing the KL divergence of maximum likelihood?
- It's exactly to minimizing the cross-entropy between the distribution.
83. Any loss consisting of a negative log-likelihood is a crossentropy between the empirical distribution defined by the training set and the probability distribution defined by model
84. Mean squared error is the cross-entropy between the empirical distribution and a Gaussian model
85. In software, we often phrase both as minimizing a cost function. Maximum likelihood thus becomes minimization of the negative log-likelihood (NLL), or equivalently, minimization of the cross entropy. The perspective of maximum likelihood as minimum KL divergence becomes helpful in this case because the KL divergence has a known minimum value of zero. The negative log-likelihood can actually become negative when x is real-valued.
86. What is the conditional probability $P(y|x;\theta)$ ?
- Predict $y$ given $x$ distributed parameterized by $\theta$

87. If $X$ represents all inputs and $Y$ is observed targets, then what is the conditional maximum likelihood estimator?
![conditional_llh.png](..\assets\conditional_llh.png)
88. If the examples are assumed to be i.i.d, what the conditional maximum likelihood estimator be?
![cond2_llh.png](..\assets\cond2_llh.png)

89. What is the property of Maximum Likelihood?
- It can be shown to be the best estimator asymptotically, as the # examples $m \to \infty$ (Under appropriate conditions, it has the property of consistency)
90. What is the two conditions for Maximum likelihood to have consistency?
- The true distribution $p_{data}$ must lie within the model family $p_{model}(.;\theta)$ 
- The true distribution $p_{data}$ must correspond to exactly one value of $\theta$ (it means that MLikelihood can only recover the correct $p_{data}$ but can't determine the value $\theta$ used for data generating processing).
-------------------------- BAYESIAN -----------------------------------------
91. What is the Bayesian perspective on statistics?
- The true parameter $\theta$ is represented as a random variable.
- The Bayesian uses probability to reflect degrees of certainty of states of knowledge.

92. What do we do before observing the data?
- Represent knowledge of $\theta$ using the prior probability distribution, $p(\theta)$ (the prior)

93. Usually, how do the machine learning practitioner select prior distribution?
- selects a prior distribution that is quite broad (i.e. with high entropy) to reflect a high degree of uncertainty in the value of $\theta$ before observing any data.

94. Consider a set of data samples $\{x^1,...,x^n\}$, how to recover the effect of data on the belief about $\theta$?
- Combining the data likelihood $p(x^1,...,x^m|\theta)$ with the prior via Bayes' rule:
![bayes_rule_theta.png](..\assets\bayes_rule_theta.png)

95. In the scenarios where Bayesian estimation is typically used, the prior begins as a relatively uniform or Gaussian distribution with high entropy, and the observation of the data usually causes the posterior to lose entropy and concentrate around a few highly likely values of the parameters.